{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpsolution = mp.solutions.holistic\n",
    "drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Superimpose(image, landmarks):\n",
    "    drawing.draw_landmarks(image, landmarks.face_landmarks, mpsolution.FACEMESH_CONTOURS, drawing.DrawingSpec(color=(80, 110, 10), thickness=1, circle_radius=1), drawing.DrawingSpec(color=(80, 256, 121), thickness=1, circle_radius=1))\n",
    "    drawing.draw_landmarks(image, landmarks.pose_landmarks, mpsolution.POSE_CONNECTIONS)\n",
    "    drawing.draw_landmarks(image, landmarks.left_hand_landmarks, mpsolution.HAND_CONNECTIONS, drawing.DrawingSpec(color=(80, 110, 10), thickness=1, circle_radius=1), drawing.DrawingSpec(color=(80, 256, 121), thickness=1, circle_radius=1))\n",
    "    drawing.draw_landmarks(image, landmarks.right_hand_landmarks, mpsolution.HAND_CONNECTIONS, drawing.DrawingSpec(color=(80, 110, 10), thickness=1, circle_radius=1), drawing.DrawingSpec(color=(80, 256, 121), thickness=1, circle_radius=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BrightnessContrast(img, brightness = 0, contrast = 0):\n",
    "     \n",
    "    # getTrackbarPos returns the current\n",
    "    # position of the specified trackbar.\n",
    "    # brightness = cv2.getTrackbarPos('Brightness', 'test')\n",
    "      \n",
    "    # contrast = cv2.getTrackbarPos('Contrast', 'test')\n",
    "  \n",
    "    effect = controller(img, brightness, contrast)\n",
    "  \n",
    "    # The function imshow displays an image\n",
    "    # in the specified window\n",
    "    return effect\n",
    "\n",
    "def controller(img, brightness=255, contrast=127):\n",
    "    brightness = int((brightness - 0) * (255 - (-255)) / (510 - 0) + (-255))\n",
    "    contrast = int((contrast - 0) * (127 - (-127)) / (254 - 0) + (-127))\n",
    "  \n",
    "    if brightness != 0:\n",
    "        if brightness > 0:\n",
    "            shadow = brightness\n",
    "            max = 255\n",
    "        else:\n",
    "            shadow = 0\n",
    "            max = 255 + brightness\n",
    "\n",
    "        al_pha = (max - shadow) / 255\n",
    "        ga_mma = shadow\n",
    "  \n",
    "        # The function addWeighted calculates\n",
    "        # the weighted sum of two arrays\n",
    "        cal = cv2.addWeighted(img, al_pha, img, 0, ga_mma)\n",
    "    else:\n",
    "        cal = img\n",
    "  \n",
    "    if contrast != 0:\n",
    "        Alpha = float(131 * (contrast + 127)) / (127 * (131 - contrast))\n",
    "        Gamma = 127 * (1 - Alpha)  \n",
    "        # The function addWeighted calculates\n",
    "        # the weighted sum of two arrays\n",
    "        cal = cv2.addWeighted(cal, Alpha, cal, 0, Gamma)\n",
    "  \n",
    "    # putText renders the specified text string in the image.\n",
    "    #cv2.putText(cal, 'B:{},C:{}'.format(brightness, contrast), (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "  \n",
    "    return cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    result = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Process(result):\n",
    "    processed = dict()\n",
    "\n",
    "    if result.pose_landmarks:\n",
    "        temp = list(result.pose_landmarks.landmark)[0]\n",
    "        landmarks = np.array([[(res.x - temp.x), (res.y - temp.y), (res.z - temp.z), res.visibility] for res in result.pose_landmarks.landmark])\n",
    "        # landmarks = np.array([[(res.x), (res.y), (res.z), res.visibility] for res in result.pose_landmarks.landmark])\n",
    "    else:\n",
    "        landmarks = np.zeros(33*4)\n",
    "\n",
    "    processed[\"pose\"] = landmarks.flatten()\n",
    "\n",
    "    if result.face_landmarks:\n",
    "        #temp = list(result.face_landmarks.landmark)[0]\n",
    "        landmarks = np.array([[(res.x - temp.x), (res.y - temp.y), (res.z - temp.z)] for res in result.face_landmarks.landmark])\n",
    "        # landmarks = np.array([[(res.x), (res.y), (res.z)] for res in result.face_landmarks.landmark])\n",
    "    else:\n",
    "        landmarks = np.zeros(468*3)\n",
    "\n",
    "    processed[\"face\"] = landmarks.flatten()\n",
    "\n",
    "    if result.right_hand_landmarks:\n",
    "        #temp = list(result.right_hand_landmarks.landmark)[0]\n",
    "        landmarks = np.array([[(res.x - temp.x), (res.y - temp.y), (res.z - temp.z)] for res in result.right_hand_landmarks.landmark])\n",
    "        # landmarks = np.array([[(res.x), (res.y), (res.z)] for res in result.right_hand_landmarks.landmark])\n",
    "    else:\n",
    "        landmarks = np.zeros(21*3)\n",
    "\n",
    "    processed[\"right_hand\"] = landmarks.flatten()\n",
    "\n",
    "    if result.left_hand_landmarks:\n",
    "        #temp = list(result.left_hand_landmarks.landmark)[0]\n",
    "        landmarks = np.array([[(res.x - temp.x), (res.y - temp.y), (res.z - temp.z)] for res in result.left_hand_landmarks.landmark])\n",
    "        # landmarks = np.array([[(res.x), (res.y), (res.z)] for res in result.left_hand_landmarks.landmark])\n",
    "    else:\n",
    "        landmarks = np.zeros(21*3)\n",
    "\n",
    "    processed[\"left_hand\"] = landmarks.flatten()\n",
    "\n",
    "    #return processed\n",
    "    # return np.concatenate([processed[\"pose\"], processed[\"face\"], processed[\"left_hand\"], processed[\"right_hand\"]])\n",
    "    return processed[\"pose\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataCollection(path, frames, videos, actions):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "\n",
    "    for action in actions:\n",
    "        os.makedirs(os.path.join(path, action))\n",
    "\n",
    "        for video in range(videos):\n",
    "            out = cv2.VideoWriter(os.path.join(path, action, \"vid%s.avi\"%video), fourcc, 25, (640, 480))\n",
    "\n",
    "            for frame in range(frames):\n",
    "                ret, image = cap.read()\n",
    "\n",
    "                if not ret:\n",
    "                    print(os.path.join(path, action, \"vid%s.avi\"%video))\n",
    "                    break\n",
    "        \n",
    "                effect = BrightnessContrast(image, 357, 209)\n",
    "\n",
    "                if frame == 0:\n",
    "                    cv2.putText(image, \"Starting Collection\", (120, 200), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 4, cv2.LINE_AA)\n",
    "                    cv2.waitKey(1000)\n",
    "\n",
    "                out.write(effect)\n",
    "        \n",
    "                cv2.imshow(\"OnlyFans!!\", effect)\n",
    "\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataCollection(\"C:\\\\Users\\\\kevin\\\\OneDrive\\\\Documents\\\\Year4\\\\ECNG3020\\\\Code\\\\data\\\\myvids\", 50, 3, [\"test1\", \"test2\", \"test3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(path, save, time):\n",
    "    count = 0\n",
    "    video = cv2.VideoCapture(path)\n",
    "    cv2.namedWindow('test')\n",
    "    cv2.createTrackbar('Brightness', 'test', 255, 2 * 255, BrightnessContrast) \n",
    "    cv2.createTrackbar('Contrast', 'test', 127, 2 * 127, BrightnessContrast)\n",
    "    \n",
    "    with mpsolution.Holistic(min_detection_confidence = 0.5, min_tracking_confidence=0.5) as model:\n",
    "        while video.isOpened():\n",
    "            ret, frame = video.read()\n",
    "            if not ret:\n",
    "                print(path)\n",
    "                break\n",
    "        \n",
    "            result1 = detection(frame, model)\n",
    "           # effect = BrightnessContrast(frame, 357, 209)\n",
    "            #result2 = detection(effect, model)\n",
    "\n",
    "            Superimpose(frame, result1)\n",
    "            #Superimpose(effect, result2)\n",
    "        \n",
    "            cv2.imshow(\"OnlyFans!!\", frame)\n",
    "            #cv2.imshow(\"effect\", effect)\n",
    "            final = Process(result1)\n",
    "            np.save(save + \"/\" + str(count), final)\n",
    "            count += 1\n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "    \n",
    "        video.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "video = cv2.VideoCapture(0)\n",
    "# cv2.namedWindow('test')\n",
    "# cv2.createTrackbar('Brightness', 'test', 255, 2 * 255, BrightnessContrast) \n",
    "# cv2.createTrackbar('Contrast', 'test', 127, 2 * 127, BrightnessContrast)\n",
    "    \n",
    "with mpsolution.Holistic(min_detection_confidence = 0.5, min_tracking_confidence=0.5) as model:\n",
    "    while video.isOpened():\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "            break\n",
    "        \n",
    "        result1 = detection(frame, model)\n",
    "        effect = BrightnessContrast(frame, 357, 209)\n",
    "        result2 = detection(effect, model)\n",
    "\n",
    "        #Superimpose(frame, result1)\n",
    "        Superimpose(effect, result2)\n",
    "        \n",
    "        cv2.imshow(\"OnlyFans!!\", frame)\n",
    "        cv2.imshow(\"effect\", effect)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"missing.txt\") as f:\n",
    "    missing = f.readlines()\n",
    "    missing = [temp.rstrip(\"\\n\") for temp in missing]\n",
    "    \n",
    "with open(\"exercise.json\") as f:\n",
    "    temp = json.load(f)\n",
    "    data = dict()\n",
    "    count = 0\n",
    "    for i in range(len(temp)):\n",
    "        temp2 = temp[i][\"instances\"].copy()\n",
    "        for x in temp[i][\"instances\"]:\n",
    "            if missing.count(x[\"video_id\"]) > 0:\n",
    "                temp2.remove(x)\n",
    "                count += 1\n",
    "        data[temp[i][\"gloss\"]] = [(temp3[\"video_id\"], temp3[\"frame_start\"], temp3[\"frame_end\"]) for temp3 in temp2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.keys()\n",
    "actions = {temp : data[temp] for temp in data}\n",
    "plt.bar(list(actions.keys()), list(len(temp) for temp in actions.values()), align='center')\n",
    "plt.xticks(range(len(actions)), list(actions.keys()))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0000.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0001.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0002.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0003.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0004.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0005.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0006.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0007.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0008.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0009.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0010.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0011.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0012.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0013.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0014.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0015.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0016.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0017.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0018.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0019.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0020.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0021.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0022.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0023.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0024.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0025.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0026.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0027.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0028.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0029.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0030.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0031.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0032.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0033.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0034.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0035.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0036.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0037.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0038.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0039.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0040.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0041.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0042.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0043.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0044.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0045.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0046.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0047.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0048.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0049.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0050.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0051.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0052.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0053.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0054.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0055.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0056.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0057.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0058.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0059.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0060.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0061.mp4\n",
      "C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/0062.mp4\n"
     ]
    }
   ],
   "source": [
    "for action in actions:\n",
    "    os.mkdir(\"videos/%s\"%action)\n",
    "    for instance in actions[action]:\n",
    "        os.mkdir(\"videos/%s/%s\"%(action, instance[0]))\n",
    "        if(os.path.exists(\"./videos/%s/%s.mp4\"%(action, instance[0]))):\n",
    "            continue\n",
    "        time = int(1000/instance[1])\n",
    "        run(\"C:/Users/kevin/OneDrive/Documents/Year4/ECNG3020/Code/data/videos/%s.mp4\"%instance[0], \"videos/%s/%s\"%(action, instance[0]), time)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jack': 0, 'squats': 1}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = {label: num for num, label in enumerate(actions)}\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [], []\n",
    "for action in actions:\n",
    "    for video in actions[action]:\n",
    "        temp = []\n",
    "        for filename in os.listdir(\"videos/%s/%s\"%(action, video[0])):\n",
    "            frame = np.load(\"videos/%s/%s/%s\"%(action, video[0], filename))\n",
    "            if len(frame) != 33*4:\n",
    "                print(\"ERROR IN videos/%s/%s/%s\"%(action, video[0], filename))\n",
    "            temp.append(frame)\n",
    "        sequences.append(temp)\n",
    "        labels.append(label_map[action])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(actions[\"jack\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = max([len(i) for i in sequences])\n",
    "for vid in sequences:\n",
    "    if len(vid) < full:\n",
    "        for i in range(full - len(vid)):\n",
    "            vid.append(np.zeros(33*4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(sequences)\n",
    "y = to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59, 284, 132)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(284, 132)))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "12/12 [==============================] - 47s 4s/step - loss: 0.6945 - categorical_accuracy: 0.4746\n",
      "Epoch 2/350\n",
      "12/12 [==============================] - 44s 4s/step - loss: 741533.6875 - categorical_accuracy: 0.5932\n",
      "Epoch 3/350\n",
      " 3/12 [======>.......................] - ETA: 31s - loss: nan - categorical_accuracy: 0.6000          "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8060/677884752.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m350\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtb_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\ECNG3020\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\ECNG3020\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\ECNG3020\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\ECNG3020\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\ECNG3020\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\ECNG3020\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\ECNG3020\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\miniconda3\\envs\\ECNG3020\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\ECNG3020\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=350, batch_size=5, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "abfeca66813848e2cdbe73d59d7314be6cb81f006f558773d81e8f09166e8732"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ECNG3020': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
